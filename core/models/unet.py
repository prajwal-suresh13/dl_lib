
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/core/models/unet.ipynb
__all__ ='icnr_init PixelShuffle_ICNR double_conv_max UnetBlock UNet'.split(" ")


from dl_lib.core.utils import *
from dl_lib.core.models.basicmodels import *

def icnr_init(x, scale=2, init=nn.init.kaiming_normal_):
    "ICNR init of `x`, with `scale` and `init` function"
    ni,nf,h,w = x.shape
    ni2 = int(ni/(scale**2))
    k = init(x.new_zeros([ni2,nf,h,w])).transpose(0, 1)
    k = k.contiguous().view(ni2, nf, -1)
    #https://stackoverflow.com/questions/48915810/what-does-contiguous-do-in-pytorch
    k = k.repeat(1, 1, scale**2) # repeat on the mentioned dim
    k = k.contiguous().view([nf,ni,h,w]).transpose(0, 1)
    return k

class PixelShuffle_ICNR(nn.Sequential):
    def __init__(self, ni, nf=None, scale=2, blur=False):
        super().__init__()
        nf = ifnone(nf, ni)
        layers = [conv_layer(ni, nf*(scale**2), ks=1, stride=1), nn.PixelShuffle(scale)]
        layers[0][0].weight.data.copy_(icnr_init(layers[0][0].weight.data))
        if blur: layers+=[nn.ReflectionPad2d((1,0,1,0)), nn.AvgPool2d(2,stride=1)]
        super().__init__(*layers)

def double_conv_max(n_in, n_out, ks=3, stride=1, maxpool=True):
    layers = [conv_layer(n_in, n_out, ks=ks, stride=stride), conv_layer(n_out, n_out,ks=ks, stride=stride)]
    if maxpool: layers+=[nn.MaxPool2d(kernel_size=2, stride=2)]
    return nn.Sequential(*layers)

class UnetBlock(nn.Module):
    def __init__(self, up_in_c, x_in_c):
        super().__init__()
        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2)
        self.bn = nn.BatchNorm2d(x_in_c)
        ni = up_in_c//2 + x_in_c
        nf = ni//2
        self.double_conv = double_conv_max(ni,nf, maxpool=False)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, up_in, hook):
        up_out = self.shuf(up_in)
        # print(up_out.shape)
        hook = hook
        # print(hook.shape)
        if hook.shape[-2:]!=up_out.shape[-2:]:
            up_out = F.interpolate(up_out, hook.shape[-2:], mode='nearest')
        cat = self.relu(torch.cat([up_out, self.bn(hook)],dim=1))
        return self.double_conv(cat)

class UNet(nn.Module):
    def __init__(self, input_channels, output_channels):
        super().__init__()
        self.input_channels, self.output_channels =input_channels, output_channels
        filters =[self.input_channels, 64, 128, 256, 512,1024]

        encoder_layers = [double_conv_max(filters[i],filters[i+1]) for i in range(4)]
        self.encoder = nn.Sequential(*encoder_layers)
        self.blocks = [enc[1] for enc in self.encoder]


        self.mid_layers = double_conv_max(filters[-2],filters[-1],maxpool=False)

        filters = list(reversed(filters))
        decoder_layers = [UnetBlock(filters[i],filters[i+1]) for i in range(4)]
        self.decoder = nn.Sequential(*decoder_layers)


        self.output_layer = nn.Conv2d(in_channels=64, out_channels= self.output_channels, kernel_size=1)

    def forward(self, image):
        with Hooks(self.blocks, hook_outputs) as hooks:
            x = self.encoder(image)
            self.hooks = [o.output for o in hooks]
        # print(x.shape)
        # for h in self.hooks: print(h.shape)

        self.hooks = list(reversed(self.hooks))

        x = self.mid_layers(x)
        # print(x.shape)

        for layer,h in zip(self.decoder, self.hooks):
            x = layer(x, h)
            # print(x.shape)
        x = self.output_layer(x)
        # print(x.shape)
        return x